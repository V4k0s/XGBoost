{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XGBoost-TESTANDO.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost\n"
      ],
      "metadata": {
        "id": "731SurN-p1Ut"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introdução\n",
        "\n",
        "<p align = \"justify\">O XGboost (Extreme Gradient Boosting) é um algoritmo de Ensemble, podendo ser pensado como uma aprimoração do Gradient Boosting. O Gradient Boosting ajusta os pesos usando o Gradient Descent (em geral olhando para uma loss function específica: MSE para algoritmos de regressão e uma função logarítmica para algoritmos de classificação), otimizando iterativamente a diferença entre o valor previsto e o valor real. Em essência, o XGBoost é um algoritmo que usa a expansão de Taylor de ordem 2 para tratar a função objetivo, tomando árvores de decisão como seus preditores. Além disso, a função objetivo do XGBoost conta com um parâmetro extra de regularização em sua construção, o qual aumenta a precisão, penaliza modelos muito complexos em detrimento de modelos mais simples e evita o temido sobreajuste (ideia que lembra muito a Ridge Regression)."
      ],
      "metadata": {
        "id": "ZtXjBY_7i3QT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fundamentação Teórica"
      ],
      "metadata": {
        "id": "ClpBfwDwqfsZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<p align = \"justify\"> Seja $\\mathcal{D}=\\{ (x_i,y_i)_{i=1}^{n}\\}⊂\\mathbb{R}^m \\times \\mathbb{R}$ uma amostra rotulada. Um modelo emsemble de árvore de decisão usa um número $K$ de funções aditivas $f_k$ para predizer o parâmetro $y_i$. Essa predição é denotada por $p_i$ e </p>\n",
        "\n",
        "$$p_i = \\sum_{k=1}^{K} f_k(x_i),\\qquad  f_k ∈ \\mathcal{F},$$\n",
        "\n",
        "em que $\\mathcal{F} = \\{f \\mid f(x) = w_{q(x)},\\, q:\\mathbb{R}^m\\to T \\text{ e } w \\in \\mathbb{R}^T\\}$\n",
        "\n",
        "<p align = \"justify\"> Cada $f_k$ corresponde a uma estrutura de árvore independente $q$ e pesos de folha $w$, com $T$ sendo o número de folhas da árvore. Ao contrário das árvores de decisão, cada árvore de regressão contém uma pontuação contínua em cada folha: os $w_i$'s são usados para representar a pontuação na $i$-ésima folha. Para cada $x_i$, usaremos as regras de decisão nas árvores (dadas por $q$) para classificá-lo nas folhas e calcular a previsão final somando a pontuação nas folhas correspondentes (dadas por $w$). Para aprender o conjunto de funções usadas no modelo, se minimiza o objetivo regularizado: </p>\n",
        "\n",
        "$$\\mathcal{L} =  \\sum_{i} l(p_i,y_i) +\\sum_{k}\\Omega(f_k)$$\n",
        "onde $$\\Omega(f) =\\gamma T + \\frac{1}{2}\\lambda \\|w\\|^2.$$ \n",
        "\n",
        "<p align = \"justify\">\n",
        "Aqui $l$ é uma $``$loss function$\"$ (convexa e diferenciável) que mede a diferença entre a previsão $p_i$ e o alvo $y_i$. O segundo termo $\\Omega$ penaliza a complexidade do modelo (ou seja, as funções da árvore de regressão). Esse termo de regularização ajuda a suavizar os pesos finais aprendidos para evitar sobreajuste (mesma ideia utilizada na construção do ridge regression visto em aula). Intuitivamente, o objetivo regularizado tenderá a selecionar um modelo empregando funções simples e preditivas. Quando o parâmetro de regularização é zerado, o objetivo volta ao tradicional Gboost. </p>\n",
        "\n",
        "Seja $p_i^{(t)}$ a previsão da $i$-ésima instância na $t$-ésima iteração. Queremos encontrar $f_t$ para minimizar\n",
        "\n",
        "$$\\mathcal{L}^{(t)} =  \\sum_{i= 1}^{n} l(y_i,p_i^{(t-1)}+f_t(x_i)) +\\Omega(f_t)$$\n",
        "Usando a expansão de Taylor de ordem 2, sabemos que \n",
        "\n",
        "$$f(a+h)≈ f(a)+f'(a)h+\\frac{1}{2}f''(a)h^2$$ para $f\\in C^2$. Se $l$ for suficientemente suave, fazemos $f=l$, $a = p_i^{(t)}$ e $h=f_t(x_i)$, obtendo assim\n",
        "\n",
        "\\begin{align}\n",
        "\\mathcal{L}^{(t)} &≈  \\sum_{i= 1}^{n} \\bigl( l(y_i,p_i^{(t-1)})+g_if_t(x_i)+\\frac{1}{2}h_i [f_t(x_i)]^2\\bigr) +\\Omega(f_t) \\\\ &= \\sum_{i= 1}^{n} \\bigl[ C+g_if_t(x_i)+\\frac{1}{2}h_i [f_t(x_i)]^2\\bigr) +\\Omega(f_t)\n",
        "\\end{align}\n",
        "em que $C$ é uma constante, \n",
        "$$g_i = \\frac{\\partial l(y_i, p_i^{(t-1)})}{\\partial p_i^{(t-1)}} \\qquad \\text{ e } \\qquad h_i = \\frac{\\partial^2 l(y_i, p_i^{(t-1)})}{\\partial p_i^{(t-1)}\\,^2 }.$$\n",
        "\n",
        "Removendo esse termo constante, nossa nova função objetivo se torna no passo $t$ igual a \n",
        "\n",
        "$$\\mathcal{L_1}(t) = \\Omega(f_t)+ \\sum_{i= 1}^{n} \\bigl(g_if_t(x_i)+\\frac{1}{2}h_i [f_t(x_i)]^2\\bigr).$$\n",
        "\n",
        "Dado $j\\in\\{1,\\dots, T\\}$, defina $I_j  = \\{i\\mid q(x_i)=j\\}$. Expandindo $\\Omega$ e retomando definição de $\\mathcal{F}$, podemos escrever\n",
        "\\begin{align}\n",
        "\\mathcal{L}_1^{(t)} &=\\gamma T + \\frac{1}{2}\\lambda \\sum_{j=1}^{T} w_j^2+\\sum_{i= 1}^{n} g_if_t(x_i)+\\frac{1}{2}h_i [f_t(x_i)]^2 \\\\& = \\gamma T + \\frac{1}{2}\\lambda \\sum_{j=1}^{T} w_j^2+ \\sum_{j= 1}^{T}\\sum_{i \\in I_j} g_iw_j+\\frac{1}{2}\\sum_{j= 1}^{T}\\sum_{i \\in I_j} h_i[w_j]^2\\\\& = \\gamma T + \\sum_{j=1}^{T} \\biggl[ \\sum_{i \\in I_j} g_iw_j+ \\frac{1}{2}w_j^2\\biggl( \\lambda + \\sum_{i \\in I_j} h_i \\biggr)\\biggr]\n",
        "\\end{align}\n",
        "\n",
        "Uma vez fixada a estrutura $q(x)$, podemos calcular para cada $j$ o peso ótimo $w_j^*$ dado por\n",
        "$$\n",
        "w_j^* = -\\frac{\\sum_{i \\in I_j} g_i}{\\lambda + \\sum_{i \\in I_j} h_i}\n",
        "$$\n",
        "<p align = \"justify\">(esse resultado pode ser obtido usando derivadas para encontrar os pontos críticos da parábola $ bx+\\frac{a}{2}x^2$). Logo, o valor ótimo correspondente é </p>\n",
        "$$\n",
        "\\mathcal{L}_1^{(t)}(q) = \\gamma T-\\frac{1}{2}\\sum_{j=1}^{T}\\frac{\\bigl(\\sum_{i \\in I_j} g_i\\bigr)^2}{\\lambda + \\sum_{i \\in I_j} h_i}\n",
        "$$\n",
        "\n",
        "<p align = \"justify\">De modo geral, não é possível enumerar todas as estruturas de árvores $q$. Em vez disso, usa-se um algoritmo ambicioso que começa a partir de uma única folha e adiciona iterativamente ramos à árvore. Se $I_L$ e $I_R$ são os conjuntos de instâncias dos nós esquerdo e direito após a divisão, então deixando $I = I_L \\cup I_R$ a redução da perda após a divisão é dada por</p>\n",
        "\n",
        "\\begin{align}\n",
        "\\mathcal{L}_{split} &= \\gamma -\\frac{1}{2}\\frac{\\bigl(\\sum_{i \\in I} g_i\\bigr)^2}{\\lambda + \\sum_{i \\in I} h_i} - \\biggl[\\gamma-\\frac{1}{2}\\frac{\\bigl(\\sum_{i \\in I_L} g_i\\bigr)^2}{\\lambda + \\sum_{i \\in I_L} h_i} + \\gamma -\\frac{1}{2}\\frac{\\bigl(\\sum_{i \\in I_R} g_i\\bigr)^2}{\\lambda + \\sum_{i \\in I_R} h_i} \\biggr]\\\\&=\\frac{1}{2}\\biggl[ \\frac{\\bigl(\\sum_{i \\in I_L} g_i\\bigr)^2}{\\lambda + \\sum_{i \\in I_L} h_i} +\\frac{\\bigl(\\sum_{i \\in I_R} g_i\\bigr)^2}{\\lambda + \\sum_{i \\in I_R} h_i} -\\frac{\\bigl(\\sum_{i \\in I} g_i\\bigr)^2}{\\lambda + \\sum_{i \\in I} h_i}\\biggr]-\\gamma.\n",
        "\\end{align}"
      ],
      "metadata": {
        "id": "Z9RV943Ppl8f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prós e contras.\n",
        "\n",
        "\n",
        "\n",
        "Prós:\n",
        "*   Alta velocidade quando comparado com outros algorítmos.\n",
        "*   Grande desempenho para dados tabulares/estruturados.\n",
        "*   O termo de regularização do algorítmo penaliza a construção de árvores complexas, evitando o sobreajuste.\n",
        "*   Pode lidar com valores ausentes.\n",
        "*   Não há necessidade de dimensionar/normalizar dados.\n",
        "\n",
        "Contras:\n",
        "*   Não explora todas as estruturas de árvore possíveis.\n",
        "*   Pode deixar a desejar se os dados não forem estruturados (ex. imagens).\n",
        "*   Se os parâmetros da função objetivo não forem ajustados corretamente, pode facilmente sobreajustar os dados.\n"
      ],
      "metadata": {
        "id": "ldaaT4p-tVqD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparando o XGboost com outros algorítmos"
      ],
      "metadata": {
        "id": "3uM28NagXYbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ],
      "metadata": {
        "id": "5oJ8v8qGZtsi"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42\n",
        "np.random.seed(seed)"
      ],
      "metadata": {
        "id": "q1QwGSXGr8nK"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def display_scores(scores):\n",
        "    print(\"Scores:\", scores)\n",
        "    print(\"Mean:\", scores.mean())\n",
        "    print(\"Standard deviation:\", scores.std())"
      ],
      "metadata": {
        "id": "YHNJY5TGXI4u"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regressão - Dataset California Housing\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4BJOtRRQWqZ4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "gf4FmNkIDRoe"
      },
      "outputs": [],
      "source": [
        "housing = pd.read_csv(\"./sample_data/california_housing_train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = housing.drop(\"median_house_value\", axis=1)\n",
        "Y = housing['median_house_value']\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, \n",
        "                                        test_size=0.3, \n",
        "                                        random_state=seed)"
      ],
      "metadata": {
        "id": "M5bUhiToZjDv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "forest_reg = RandomForestRegressor(max_features=8, n_estimators=30, random_state=seed)\n",
        "forest_scores = cross_val_score(forest_reg, X_train, Y_train,\n",
        "                                scoring=\"neg_mean_squared_error\", cv=10)\n",
        "forest_rmse_scores = np.sqrt(-forest_scores)\n",
        "display_scores(forest_rmse_scores)"
      ],
      "metadata": {
        "id": "owrKme88Rvlv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ee394c7-98dc-41a9-ab8c-bcc2a2948e6a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scores: [48277.93131024 48843.55962478 53109.92636919 48971.14767998\n",
            " 49522.5483048  51276.51797027 50051.96237318 47143.98927561\n",
            " 52535.15723245 50521.64507908]\n",
            "Mean: 50025.4385219577\n",
            "Standard deviation: 1781.647390067774\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "xg_reg = XGBRegressor(learning_rate=0.08, \n",
        "                                 n_estimators=1300,\n",
        "                                 max_depth=6,\n",
        "                                 random_state=seed,\n",
        "                                 gpu_id='0',\n",
        "                                 booster=\"gbtree\",\n",
        "                                 warm_start = True,\n",
        "                                 objective='reg:squarederror'\n",
        "                                 ) \n",
        "\n",
        "xg_scores = cross_val_score(xg_reg, X_train, Y_train,\n",
        "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
        "xg_rmse_scores = np.sqrt(-xg_scores)\n",
        "display_scores(xg_rmse_scores)"
      ],
      "metadata": {
        "id": "idwUZmQQbHb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b2d9040-a560-4c9a-c2f5-13e02e2c40bc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scores: [44991.8077535  46228.63207701 48594.16721061 45305.60823664\n",
            " 46195.47471453 45645.70148828 45690.11241333 44103.25746412\n",
            " 51204.14302396 47507.3592668 ]\n",
            "Mean: 46546.62636487592\n",
            "Standard deviation: 1962.275229896435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xg_reg.fit(X_train, Y_train)\n",
        "y_pred = xg_reg.predict(X_test)\n",
        "\n",
        "np.sqrt(MSE(Y_test, y_pred))"
      ],
      "metadata": {
        "id": "a3PY5z0B0rjP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bda59b08-a80d-41c2-9698-9fe097258d63"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46893.80851296068"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Classificação - Dataset Iris"
      ],
      "metadata": {
        "id": "hwPBIowicn3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "\n",
        "x = iris.data\n",
        "y = iris.target\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, \n",
        "                                        test_size=0.3, \n",
        "                                        random_state=seed)"
      ],
      "metadata": {
        "id": "XBARCB-rcn_H"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "trclf = DecisionTreeClassifier(random_state=seed, max_depth=2)\n",
        "\n",
        "trclf_scores = cross_val_score(trclf, x_train, y_train, cv=10, scoring='accuracy')\n",
        "print(trclf_scores)"
      ],
      "metadata": {
        "id": "-4Z8GJKPSR2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22524d90-1df7-4620-ae80-c88d722d82f6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.90909091 1.         1.         0.72727273 0.81818182 1.\n",
            " 1.         0.9        0.9        0.9       ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trclf.fit(x_train, y_train)\n",
        "y_pred = trclf.predict(x_test)\n",
        "\n",
        "print(accuracy_score(y_test,y_pred))"
      ],
      "metadata": {
        "id": "oAK59BHAS652",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dee8b052-5103-4a9c-e4c5-5ea863132303"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9777777777777777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "xgclf = XGBClassifier(random_state=seed, max_depth=2)\n",
        "\n",
        "xgclf_scores = cross_val_score(xgclf, x_train, y_train, cv=10, scoring='accuracy')\n",
        "print(xgclf_scores)"
      ],
      "metadata": {
        "id": "6cTc6TJVfm6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c87392f-e6c3-430c-eb1d-c7c9e84e2995"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.90909091 1.         0.90909091 0.81818182 0.81818182 1.\n",
            " 1.         1.         1.         0.9       ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgclf.fit(x_train, y_train)\n",
        "y_pred = xgclf.predict(x_test)\n",
        "\n",
        "print(accuracy_score(y_test,y_pred))"
      ],
      "metadata": {
        "id": "YCPqjBgogZ7p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c3020d4-fa34-46e2-d82c-2d710d7016da"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    }
  ]
}